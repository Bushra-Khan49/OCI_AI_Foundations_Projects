# Step-by-Step Code with Explanations

### Step 1: Import Libraries
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_circles
from sklearn.neural_network import MLPClassifier
import ipywidgets as widgets
from IPython.display import display
from ipywidgets import interactive
```
- Why?: These imports provide tools for data generation (make_circles), modeling (MLPClassifier), plotting (plt), and interactivity (widgets, interactive). We use np for arrays and grids, essential for predictions.


## Step 2: Define the Update Function for the Plot
```
def update_plot(hidden_layer_size):
    # Generate synthetic data (circles)
    X, y = make_circles(n_samples=300, noise=0.01, factor=0.5, random_state=0)
    
    # Create the MLP Classifier
    clf = MLPClassifier(hidden_layer_sizes=(hidden_layer_size,), activation='relu', max_iter=3000, random_state=1)
    
    # Fit the classifier to the data
    clf.fit(X, y)
```
- Why?: This function is called whenever the slider changes. We generate the dataset inside for consistency (300 samples with noise for realism, factor=0.5 for interlocking circles). The MLP is recreated with the new hidden layer size (tuple for one layer), ReLU for non-linearity, high max_iter for convergence, and random_state for reproducibility. Fitting trains the model on X (features) and y (labels).


## Step 3: Create the Grid for Visualization
```
    # Create a grid of points for visualization
    x_vals = np.linspace(X[:, 0].min() - 0.1, X[:, 0].max() + 0.1, 100)
    y_vals = np.linspace(X[:, 1].min() - 0.1, X[:, 1].max() + 0.1, 100)
    X_plane, Y_plane = np.meshgrid(x_vals, y_vals)
    
    # Grid points in a single 2D array
    grid_points = np.column_stack((X_plane.ravel(), Y_plane.ravel()))
```
- Why?: To visualize the decision boundary, we need a dense grid covering the data range (with padding via -0.1/+0.1). linspace creates 1D arrays, meshgrid turns them into 2D coordinates (100x100 grid = 10,000 points). column_stack and ravel flatten it into a (10000, 2) array for predictions, as the model expects 2D input.


## Step 4: Predict on Grid and Original Data
```
    # Predict class labels for grid points (for decision boundary)
    Z = clf.predict(grid_points)
    Z = Z.reshape(X_plane.shape)
    
    # Predict class labels for original data points
    y_pred = clf.predict(X)
```
- Why?: predict on grid_points gives labels for the entire plane, reshaped back to 100x100 for contour plotting. Predicting on original X checks accuracy visually (though not plotted here, it’s for potential use).


## Step 5: Clear and Plot the Decision Boundary
```
    # Clear previous plot
    plt.clf()
    
    # Plot the decision boundary
    plt.contourf(X_plane, Y_plane, Z, alpha=0.3)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')
    plt.title(f'Decision Boundary with Hidden Layer Size: {hidden_layer_size}')
    plt.show()
```
- Why?: clf() clears the current figure for updates. contourf fills the boundary regions with colors (alpha=0.3 for transparency). scatter plots original points colored by true labels (c=y) with black edges for visibility. Title shows the parameter. show() displays the plot.


## Step 6: Create Interactive Slider
```
# Interactive widget
interactive_plot = interactive(update_plot, hidden_layer_size=widgets.IntSlider(min=1, max=50, step=1, value=10))
display(interactive_plot)
```
- Why?: interactive links the slider to the function, retriggering on change. Slider ranges from 1-50 neurons (default 10). display shows it in Jupyter.


## Conclusion

- Successfully completed the **make_circles binary classification project** as part of the Oracle Cloud Infrastructure (OCI) AI Foundations Course completion on November 11, 2025.

- Implemented a fully functional MLPClassifier that effectively learns the complex non-linear boundary of the interlocking circles dataset.

- Built an interactive Jupyter notebook with a slider to adjust hidden layer size, allowing real-time observation of how the decision boundary becomes increasingly flexible and curved as more neurons are added.

- The visualization clearly shows the transition from a straight line (few neurons) to a smooth, near-perfect circular boundary that wraps around the inner cluster — exactly demonstrating the power of neural networks on non-linear data.
